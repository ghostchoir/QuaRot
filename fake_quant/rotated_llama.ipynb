{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\"\n",
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from rotation_utils import random_orthogonal_matrix\n",
    "from hadamard_utils import random_hadamard_matrix, apply_exact_had_to_linear\n",
    "from quant_utils import ActQuantWrapper, find_qlayers, add_actquant\n",
    "\n",
    "import utils\n",
    "import model_utils\n",
    "import data_utils\n",
    "import transformers\n",
    "import quant_utils\n",
    "import rotation_utils\n",
    "import gptq_utils\n",
    "import eval_utils\n",
    "import hadamard_utils\n",
    "\n",
    "import rotated_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1 = torch.load('R1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_R1 = torch.load('/ceph/echoi/codes/QuaRot/fake_quant/rotations/SpinQuant_m_gptq_b2_R1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5452)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((R1 - learned_R1) < 1e-4).sum() / R1.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print((torch.matmul(R1, R1.T) - torch.eye(R1.size(0))).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5060)\n",
      "tensor(0.5098)\n",
      "tensor(0.5211)\n",
      "tensor(0.5203)\n",
      "tensor(0.5075)\n",
      "tensor(0.5137)\n",
      "tensor(0.5125)\n",
      "tensor(0.5068)\n",
      "tensor(0.4995)\n",
      "tensor(0.5068)\n",
      "tensor(0.5054)\n",
      "tensor(0.4968)\n",
      "tensor(0.5099)\n",
      "tensor(0.5151)\n",
      "tensor(0.5022)\n",
      "tensor(0.5079)\n",
      "tensor(0.5039)\n",
      "tensor(0.5012)\n",
      "tensor(0.5147)\n",
      "tensor(0.5045)\n",
      "tensor(0.5046)\n",
      "tensor(0.5077)\n",
      "tensor(0.5051)\n",
      "tensor(0.5196)\n",
      "tensor(0.5108)\n",
      "tensor(0.5031)\n",
      "tensor(0.5071)\n",
      "tensor(0.5009)\n",
      "tensor(0.5020)\n",
      "tensor(0.5027)\n",
      "tensor(0.5002)\n",
      "tensor(0.5068)\n"
     ]
    }
   ],
   "source": [
    "R2s = torch.load('R2s.pt')\n",
    "learned_R2s = []\n",
    "\n",
    "for i in range(32):\n",
    "    R2 = torch.load(f'rotations/SpinQuant_m_gptq_b2_R2_{i}.pt')\n",
    "    print(((R2s[i] - R2) < 1e-4).sum() / R2.numel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 128, 128])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2s.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.381253829032868e-06\n",
      "4.381253832105949e-06\n",
      "4.381253831644226e-06\n",
      "4.381253830711715e-06\n",
      "4.381253830295746e-06\n",
      "4.38125383091246e-06\n",
      "4.38125383249077e-06\n",
      "4.381253829978891e-06\n",
      "4.381253831519326e-06\n",
      "4.381253830038432e-06\n",
      "4.381253829899381e-06\n",
      "4.381253828759852e-06\n",
      "4.381253830187057e-06\n",
      "4.381253832988036e-06\n",
      "4.381253829727632e-06\n",
      "4.381253830506247e-06\n",
      "4.381253829962314e-06\n",
      "4.381253829684758e-06\n",
      "4.3812538310376335e-06\n",
      "4.381253829330392e-06\n",
      "4.381253829407568e-06\n",
      "4.381253830940215e-06\n",
      "4.381253830244776e-06\n",
      "4.381253829419293e-06\n",
      "4.381253829949258e-06\n",
      "4.381253828830792e-06\n",
      "4.381253831584867e-06\n",
      "4.381253831533204e-06\n",
      "4.3812538313707e-06\n",
      "4.381253830409103e-06\n",
      "4.381253830225992e-06\n",
      "4.381253831102901e-06\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(R2s)):\n",
    "    print((torch.matmul(R2s[i], R2s[i].T) - torch.eye(R2s[i].size(0))).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.191814676716455e-05\n",
      "-2.555238878707078e-06\n",
      "-2.5665923312333804e-06\n",
      "-2.560000028607973e-06\n",
      "-2.559999995922207e-06\n",
      "-2.5599999623935295e-06\n",
      "-2.5599999707469168e-06\n",
      "-2.559999946718113e-06\n",
      "-2.5600002815259817e-06\n",
      "-2.560000858826697e-06\n",
      "-2.5600000005435076e-06\n",
      "-2.5599999631534595e-06\n",
      "-2.560007021463766e-06\n",
      "-2.560000381007865e-06\n",
      "-2.5600000345841046e-06\n",
      "-2.559987751149775e-06\n",
      "-2.5600008967903782e-06\n",
      "-2.560000014940212e-06\n",
      "-2.5600000586382385e-06\n",
      "-2.559999950954702e-06\n",
      "-2.5599999533982548e-06\n",
      "-2.5599999366024706e-06\n",
      "-2.5599997960222475e-06\n",
      "-2.5600053767368696e-06\n",
      "-2.5599999238307414e-06\n",
      "-2.5599999655497386e-06\n",
      "-2.5599999905528184e-06\n",
      "-2.559998568072487e-06\n",
      "-2.5599996680228162e-06\n",
      "-2.559999948066079e-06\n",
      "-2.5600015085024028e-06\n",
      "-2.5600007700122736e-06\n",
      "-2.5600000223906066e-06\n"
     ]
    }
   ],
   "source": [
    "for R in [R1] + R2s:\n",
    "    print((torch.matmul(R, R.T) - torch.eye(R.size(0))).sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arguments: \n",
      "{'a_asym': False,\n",
      " 'a_bits': 16,\n",
      " 'a_clip_ratio': 1.0,\n",
      " 'a_groupsize': -1,\n",
      " 'act_order': False,\n",
      " 'bsz': 1,\n",
      " 'cal_dataset': 'wikitext2',\n",
      " 'capture_layer_io': False,\n",
      " 'distribute': False,\n",
      " 'eval_dataset': 'wikitext2',\n",
      " 'fp32_had': False,\n",
      " 'hf_token': None,\n",
      " 'int8_down_proj': False,\n",
      " 'k_asym': False,\n",
      " 'k_bits': 4,\n",
      " 'k_clip_ratio': 1.0,\n",
      " 'k_groupsize': -1,\n",
      " 'k_pre_rope': False,\n",
      " 'layer_idx': 10,\n",
      " 'learn_r1': True,\n",
      " 'learn_r2': True,\n",
      " 'lm_eval': False,\n",
      " 'lm_eval_batch_size': 128,\n",
      " 'load_qmodel_path': None,\n",
      " 'model': 'meta-llama/Llama-2-7b-hf',\n",
      " 'momentum': 0.0,\n",
      " 'nsamples': 128,\n",
      " 'percdamp': 0.01,\n",
      " 'prefix_r': '',\n",
      " 'rotate': True,\n",
      " 'rotate_mode': 'hadamard',\n",
      " 'rotation_seed': -1,\n",
      " 'save_name': '20240621_092322',\n",
      " 'save_path': '/ceph/echoi/codes/QuaRot/fake_quant/experiments/meta-llama/Llama-2-7b-hf/20240621_092322',\n",
      " 'save_qmodel_path': None,\n",
      " 'seed': 0,\n",
      " 'tasks': ['piqa',\n",
      "           'hellaswag',\n",
      "           'arc_easy',\n",
      "           'arc_challenge',\n",
      "           'winogrande',\n",
      "           'lambada'],\n",
      " 'v_asym': False,\n",
      " 'v_bits': 4,\n",
      " 'v_clip_ratio': 1.0,\n",
      " 'v_groupsize': -1,\n",
      " 'w_asym': False,\n",
      " 'w_bits': 16,\n",
      " 'w_clip': True,\n",
      " 'w_groupsize': -1,\n",
      " 'w_rtn': False,\n",
      " 'wandb': False,\n",
      " 'wandb_id': None,\n",
      " 'wandb_project': None}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "args = utils.parser_gen('--model meta-llama/Llama-2-7b-hf --rotate --a_bits 4 --v_bits 4 --k_bits 4 --w_bits 16 --w_clip --bsz 1'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data_utils.get_loaders(\n",
    "    args.cal_dataset, nsamples=args.nsamples,\n",
    "    seed=args.seed, model=args.model,\n",
    "    seqlen=2048, eval_mode=True\n",
    ")\n",
    "\n",
    "from transformers.trainer_pt_utils import LabelSmoother\n",
    "label_smoother = LabelSmoother(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.74it/s]\n",
      "---> Loading meta-llama/Llama-2-7b-hf Model with seq_len: 2048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 50758680576, 1: 50758680576, 2: 50758680576, 3: 50758680576, 4: 50758680576, 5: 50758680576, 6: 50758680576, 7: 50758680576, 'cpu': 238095507456}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU memory (from distribute_model): 12.63 -> 12.63 GB (0.00 GB)\n"
     ]
    }
   ],
   "source": [
    "transformers.set_seed(args.seed)\n",
    "model = model_utils.get_model(args.model, args.hf_token)\n",
    "model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "    \n",
    "utils.distribute_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rotated_llama import RotatedLlamaForCausalLM\n",
    "with torch.no_grad():\n",
    "    rotated_model = RotatedLlamaForCausalLM(model.config, model)\n",
    "#del model\n",
    "rotated_model.eval()\n",
    "rotation_utils.fuse_layer_norms(rotated_model)\n",
    "for p in rotated_model.parameters():\n",
    "    p.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_utils.add_actquant(\n",
    "    rotated_model,\n",
    "    layers=[nn.Linear,\n",
    "            ActQuantWrapper,\n",
    "            rotated_llama.RotatedLinear,\n",
    "            rotated_llama.RotatedOVProj]\n",
    ")\n",
    "\n",
    "qlayers = quant_utils.find_qlayers(\n",
    "    rotated_model.model,\n",
    "    layers=[nn.Linear,\n",
    "            ActQuantWrapper,\n",
    "            rotated_llama.RotatedLinear,\n",
    "            rotated_llama.RotatedOVProj]\n",
    ")\n",
    "\n",
    "for name in qlayers:\n",
    "    if 'down_proj' in name:\n",
    "        had_K, K = hadamard_utils.get_hadK(rotated_model.config.intermediate_size)\n",
    "        hadamard_utils.apply_exact_had_to_linear(qlayers[name].module, had_dim=-1, output=False)\n",
    "        qlayers[name].online_full_had = True\n",
    "        qlayers[name].had_K = had_K\n",
    "        qlayers[name].K = K\n",
    "        qlayers[name].fp32_had = args.fp32_had\n",
    "\n",
    "\n",
    "if args.w_bits < 16:\n",
    "    save_dict = {}\n",
    "    if args.load_qmodel_path: # Load Quantized Rotated Model\n",
    "        assert args.rotate, \"Model should be rotated to load a quantized model!\"\n",
    "        assert not args.save_qmodel_path, \"Cannot save a quantized model if it is already loaded!\"\n",
    "        print(\"Load quantized model from \", args.load_qmodel_path)\n",
    "        save_dict = torch.load(args.load_qmodel_path)\n",
    "        rotated_model.load_state_dict(save_dict[\"model\"])\n",
    "        \n",
    "    elif not args.w_rtn: # GPTQ Weight Quantization\n",
    "        assert \"llama\" in args.model, \"Only llama is supported for GPTQ!\"\n",
    "        \n",
    "        trainloader = data_utils.get_loaders(\n",
    "            args.cal_dataset, nsamples=args.nsamples,\n",
    "            seed=args.seed, model=args.model,\n",
    "            seqlen=model.seqlen, eval_mode=False\n",
    "        )\n",
    "        quantizers = gptq_utils.gptq_fwrd(\n",
    "            rotated_model,\n",
    "            trainloader,\n",
    "            utils.DEV,\n",
    "            args,\n",
    "            [rotated_llama.RotatedLinear, rotated_llama.RotatedOVProj])\n",
    "        save_dict[\"w_quantizers\"] = quantizers\n",
    "    else: # RTN Weight Quantization\n",
    "        quantizers = gptq_utils.rtn_fwrd(rotated_model, utils.DEV, args)\n",
    "        save_dict[\"w_quantizers\"] = quantizers\n",
    "        \n",
    "    if args.save_qmodel_path:\n",
    "        save_dict[\"model\"] = model.state_dict()\n",
    "        torch.save(save_dict, args.save_qmodel_path)\n",
    "\n",
    "\n",
    "if args.a_bits < 16 or args.v_bits < 16:\n",
    "    qlayers = quant_utils.find_qlayers(rotated_model, layers=[quant_utils.ActQuantWrapper])\n",
    "    down_proj_groupsize = -1\n",
    "    if args.a_groupsize > 0 and \"llama\" in args.model:\n",
    "        down_proj_groupsize = utils.llama_down_proj_groupsize(rotated_model, args.a_groupsize)\n",
    "    \n",
    "    for name in qlayers:            \n",
    "        layer_input_bits = args.a_bits\n",
    "        layer_groupsize = args.a_groupsize\n",
    "        layer_a_sym = not(args.a_asym)\n",
    "        layer_a_clip = args.a_clip_ratio\n",
    "        \n",
    "        if 'v_proj' in name and args.v_bits < 16: #Set the v_proj precision\n",
    "            qlayers[name].out_quantizer.configure(bits=args.v_bits,\n",
    "                                            groupsize=args.v_groupsize,\n",
    "                                            sym=not(args.v_asym),\n",
    "                                            clip_ratio=args.v_clip_ratio)\n",
    "        \n",
    "        if 'lm_head' in name: #Skip lm_head quantization   \n",
    "            layer_input_bits = 16\n",
    "        \n",
    "        if 'down_proj' in name: #Set the down_proj precision\n",
    "            if args.int8_down_proj:\n",
    "                layer_input_bits = 8\n",
    "            layer_groupsize = down_proj_groupsize\n",
    "\n",
    "            \n",
    "        qlayers[name].quantizer.configure(bits=layer_input_bits,\n",
    "                                            groupsize=layer_groupsize,\n",
    "                                            sym=layer_a_sym,\n",
    "                                            clip_ratio=layer_a_clip)\n",
    "\n",
    "\n",
    "if args.k_bits < 16:\n",
    "    if args.k_pre_rope:\n",
    "        raise NotImplementedError(\"Pre-RoPE quantization is not supported yet!\")\n",
    "    else:\n",
    "        rope_function_name = model_utils.get_rope_function_name(rotated_model)\n",
    "        layers = model_utils.get_layers(rotated_model)\n",
    "        k_quant_config = {'k_bits':args.k_bits, \"k_groupsize\": args.k_groupsize,\n",
    "                                        \"k_sym\": not(args.k_asym), \"k_clip_ratio\": args.k_clip_ratio}\n",
    "        for layer in layers:\n",
    "            rotation_utils.add_qk_rotation_wrapper_after_function_call_in_forward(\n",
    "                        layer.self_attn, \n",
    "                        rope_function_name, \n",
    "                        config=rotated_model.config,\n",
    "                        **k_quant_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 45612269568, 1: 45809401856, 2: 45809401856, 3: 45809401856, 4: 45809401856, 5: 45809401856, 6: 43827593216, 7: 50758680576, 'cpu': 237826465792}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU memory (from distribute_model): 26.45 -> 26.45 GB (0.00 GB)\n"
     ]
    }
   ],
   "source": [
    "utils.distribute_model(rotated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = model(trainloader['input_ids'][:, :2048])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = random_hadamard_matrix(model.config.hidden_size, utils.DEV).to(dtype=torch.float64)\n",
    "q2s = []\n",
    "for i in range(32):\n",
    "    q2s.append(random_hadamard_matrix(model.config.hidden_size // model.config.num_attention_heads, utils.DEV).to(dtype=torch.float64))\n",
    "q2s = torch.stack(q2s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = rotated_model(trainloader['input_ids'][:, :2048], R1=q1, R2s=q2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2828e+01, -7.3867e+00, -4.6729e-01,  ..., -6.7734e+00,\n",
       "          -8.0156e+00, -7.5000e+00],\n",
       "         [-6.4492e+00,  2.7090e+00,  4.7500e+00,  ...,  4.3750e+00,\n",
       "           5.2783e-01,  3.3965e+00],\n",
       "         [-1.1141e+01, -4.4258e+00,  3.6426e+00,  ..., -5.2930e+00,\n",
       "          -5.5977e+00, -2.5527e+00],\n",
       "         ...,\n",
       "         [-7.4805e+00, -1.0617e+01,  2.2520e+00,  ..., -5.1367e+00,\n",
       "          -5.3906e+00, -3.2617e+00],\n",
       "         [-3.9453e+00, -6.8945e+00,  5.7305e+00,  ..., -3.1074e+00,\n",
       "          -7.5493e-03,  4.8682e-01],\n",
       "         [-2.8789e+00, -3.5391e+00,  9.4062e+00,  ..., -1.0967e+00,\n",
       "           4.6826e-01, -2.6978e-01]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-15.0938,  -5.7812,   2.3984,  ...,  -5.9688,  -8.0703,  -7.7617],\n",
       "         [ -6.1367,   2.5801,   5.0078,  ...,   5.0117,   0.8262,   3.8789],\n",
       "         [-10.2031,  -4.7773,   5.4688,  ...,  -3.6602,  -3.8125,  -0.4397],\n",
       "         ...,\n",
       "         [ -7.9609, -11.2344,   1.6582,  ...,  -5.3398,  -5.9180,  -3.7461],\n",
       "         [ -3.5176,  -6.5391,   5.8984,  ...,  -2.7578,   0.0967,   0.9409],\n",
       "         [ -2.7266,  -3.2832,   9.0859,  ...,  -0.5991,   0.4150,  -0.1166]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"meta-llama/Llama-2-7b-hf\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 4096,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"num_key_value_heads\": 32,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.36.0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model._use_sdpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.modeling_llama.LlamaSdpaAttention"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.model.layers[0].self_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
