{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export CUDA_VISIBLE_DEVICES=0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4,5,6,7\"\n",
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rotation_utils import random_orthogonal_matrix\n",
    "from hadamard_utils import random_hadamard_matrix, apply_exact_had_to_linear\n",
    "from quant_utils import ActQuantWrapper\n",
    "\n",
    "import utils\n",
    "import model_utils\n",
    "import data_utils\n",
    "import transformers\n",
    "import quant_utils\n",
    "import rotation_utils\n",
    "import gptq_utils\n",
    "import eval_utils\n",
    "import hadamard_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotatedEmbedding(nn.Embedding):\n",
    "    \n",
    "    def forward(self, x, Q=None):\n",
    "        W = self.weight\n",
    "        if Q is not None:\n",
    "            W_ = torch.matmul(W, Q)\n",
    "        else:\n",
    "            W_ = W\n",
    "        \n",
    "        return F.embedding(\n",
    "            x, W_,\n",
    "            self.padding_idx,\n",
    "            self.max_norm,\n",
    "            self.norm_type,\n",
    "            self.scale_grad_by_freq,\n",
    "            self.sparse)\n",
    "\n",
    "class RotatedHead(nn.Linear):\n",
    "    \n",
    "    def forward(self, x, Q=None):\n",
    "        W = self.weight\n",
    "        \n",
    "        if Q is not None:\n",
    "            W_ = torch.matmul(W, Q)\n",
    "        else:\n",
    "            W_ = W\n",
    "        \n",
    "        return F.linear(\n",
    "            x, W_,\n",
    "        )\n",
    "\n",
    "class RotatedLinearIn(nn.Linear):\n",
    "    def forward(self, x, Q=None):\n",
    "        W = self.weight\n",
    "        \n",
    "        if Q is not None:\n",
    "            W_ = torch.matmul(W, Q)\n",
    "        else:\n",
    "            W_ = W\n",
    "        \n",
    "        return F.linear(\n",
    "            x, W_,\n",
    "        )\n",
    "\n",
    "class RotatedLinearOut(nn.Linear):\n",
    "    def forward(self, x, Q=None):\n",
    "        W = self.weight\n",
    "        b = self.bias\n",
    "        \n",
    "        if Q is not None:\n",
    "            W_ = torch.matmul(Q.T, W)\n",
    "            if b is not None:\n",
    "                b_ = torch.matmul(Q.T, b)\n",
    "            else:\n",
    "                b_ = b\n",
    "        else:\n",
    "            W_ = W\n",
    "            b_ = b\n",
    "        \n",
    "        return F.linear(\n",
    "            x, W_, b_\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RotatedEmbedding(nn.Embedding):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_embeddings,\n",
    "        embedding_dim,\n",
    "        padding_idx=None,\n",
    "        max_norm=None,\n",
    "        norm_type=2.0,\n",
    "        scale_grad_by_freq=False,\n",
    "        sparse=False,\n",
    "        _weight=None,\n",
    "        _freeze=False,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "        Q=None):\n",
    "        super().__init__(num_embeddings, embedding_dim, padding_idx,\n",
    "                         max_norm, norm_type, scale_grad_by_freq, sparse,\n",
    "                         _weight, _freeze, device, dtype)\n",
    "        \n",
    "        if Q is not None:\n",
    "            self.register_buffer(\"Q\", Q)\n",
    "        else:\n",
    "            self.Q = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        W = self.weight\n",
    "        if self.Q is not None:\n",
    "            W_ = torch.matmul(W.to(dtype=self.Q.dtype), self.Q.to(W.device)).to(dtype=W.dtype)\n",
    "            #print('emb')\n",
    "            #print(W_.grad_fn)\n",
    "        else:\n",
    "            W_ = W\n",
    "            \n",
    "        return F.embedding(\n",
    "            x, W_,\n",
    "            self.padding_idx,\n",
    "            self.max_norm,\n",
    "            self.norm_type,\n",
    "            self.scale_grad_by_freq,\n",
    "            self.sparse)\n",
    "\n",
    "class RotatedHead(nn.Linear):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        bias=True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "        Q=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "    \n",
    "        if Q is not None:\n",
    "            self.register_buffer(\"Q\", Q)\n",
    "        else:\n",
    "            self.Q = None\n",
    "    \n",
    "    def forward(self, x, Q=None):\n",
    "        W = self.weight\n",
    "        \n",
    "        if self.Q is not None:\n",
    "            W_ = torch.matmul(W.to(dtype=self.Q.dtype), self.Q.to(W.device)).to(dtype=W.dtype)\n",
    "            \n",
    "            #print('head')\n",
    "            #print(W_.grad_fn)\n",
    "        else:\n",
    "            W_ = W\n",
    "        \n",
    "        return F.linear(\n",
    "            x, W_,\n",
    "        )\n",
    "\n",
    "class RotatedLinearIn(nn.Linear):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        bias=True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "        Q=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "    \n",
    "        if Q is not None:\n",
    "            self.register_buffer(\"Q\", Q)\n",
    "        else:\n",
    "            self.Q = None\n",
    "    \n",
    "    def forward(self, x, Q=None):\n",
    "        W = self.weight\n",
    "        \n",
    "        if self.Q is not None:\n",
    "            W_ = torch.matmul(W.to(dtype=self.Q.dtype), self.Q.to(W.device)).to(dtype=W.dtype)\n",
    "            \n",
    "            #print('linear in')\n",
    "            #print(W_.grad_fn)\n",
    "        else:\n",
    "            W_ = W\n",
    "        \n",
    "        return F.linear(\n",
    "            x, W_,\n",
    "        )\n",
    "\n",
    "\n",
    "class RotatedOVProj(nn.Linear):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        bias=True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "        Qin=None,\n",
    "        Qout=None,\n",
    "        output=False,\n",
    "        nheads=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "    \n",
    "        if Qin is not None:\n",
    "            self.register_buffer(\"Qin\", Qin)\n",
    "        else:\n",
    "            self.Qin = None\n",
    "        \n",
    "        if Qout is not None:\n",
    "            self.register_buffer(\"Qout\", Qout)\n",
    "        else:\n",
    "            self.Qout = None\n",
    "        \n",
    "        self.output = output\n",
    "        self.nheads = nheads\n",
    "    \n",
    "    def forward(self, x):\n",
    "        W = self.weight\n",
    "        \n",
    "        # O\n",
    "        if self.Qin is not None:\n",
    "            if self.output:\n",
    "                W_ = torch.matmul(W.to(dtype=self.Qin.dtype), self.Qin.to(W.device)).to(dtype=W.dtype)\n",
    "            else:\n",
    "                W_ = W.to(dtype=self.Qin.dtype).reshape(W.size(0), self.nheads, -1)\n",
    "                W_ = torch.einsum('inh,hj->inj', W_, self.Qin.to(W.device)).reshape(W.size(0), -1).to(dtype=W.dtype)\n",
    "                \n",
    "                #print('linear o')\n",
    "                #print(W_.grad_fn)\n",
    "        else:\n",
    "            W_ = W\n",
    "        \n",
    "        # V\n",
    "        if self.Qout is not None:\n",
    "            if self.output:\n",
    "                W_ = W_.to(dtype=self.Qout.dtype).reshape(self.nheads, -1, W.size(1))\n",
    "                W_ = torch.einsum('ih,nhj->nij', self.Qout.to(W.device).T, W_).reshape(W.size(0), -1).to(dtype=W.dtype)\n",
    "                \n",
    "                #print('linear v')\n",
    "                #print(W_.grad_fn)\n",
    "            else:\n",
    "                W_ = torch.matmul(self.Qout.to(W.device).T, W_.to(dtype=self.Qout.dtype)).to(dtype=W.dtype)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        return F.linear(\n",
    "            x, W_,\n",
    "        )\n",
    "\n",
    "\n",
    "class RotatedLinearOut(nn.Linear):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        bias=True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "        Q=None):\n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "    \n",
    "        if Q is not None:\n",
    "            self.register_buffer(\"Q\", Q)\n",
    "        else:\n",
    "            self.Q = None\n",
    "    \n",
    "    def forward(self, x, Q=None):\n",
    "        W = self.weight\n",
    "        b = self.bias\n",
    "        \n",
    "        if self.Q is not None:\n",
    "            W_ = torch.matmul(self.Q.to(W.device).T, W.to(dtype=self.Q.dtype)).to(dtype=W.dtype)\n",
    "            \n",
    "            #print('linear out')\n",
    "            #print(W_.grad_fn)\n",
    "            if b is not None:\n",
    "                b_ = torch.matmul(self.Q.to(W.device).T, b.to(dtype=self.Q.dtype)).to(dtype=b.dtype)\n",
    "            else:\n",
    "                b_ = b\n",
    "        else:\n",
    "            W_ = W\n",
    "            b_ = b\n",
    "        \n",
    "        return F.linear(\n",
    "            x, W_, b_\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_embeddings(model, Q):\n",
    "    \n",
    "    original_emb = model.model.embed_tokens\n",
    "    \n",
    "    new_emb = RotatedEmbedding(\n",
    "        original_emb.num_embeddings,\n",
    "        original_emb.embedding_dim,\n",
    "        original_emb.padding_idx,\n",
    "        original_emb.max_norm,\n",
    "        original_emb.norm_type,\n",
    "        original_emb.scale_grad_by_freq,\n",
    "        original_emb.sparse,\n",
    "        original_emb.weight.data,\n",
    "        not original_emb.weight.requires_grad,\n",
    "        original_emb.weight.data.device,\n",
    "        original_emb.weight.data.dtype,\n",
    "        Q\n",
    "    )\n",
    "    \n",
    "    setattr(model.model, 'embed_tokens', new_emb)\n",
    "\n",
    "\n",
    "def rotate_attention_inputs(layer, Q) -> None:\n",
    "    # Rotate the WQ, WK and WV matrices of the self-attention layer.\n",
    "    for name in ['q_proj', 'k_proj']:#, 'v_proj']:\n",
    "        original_matrix = getattr(layer.self_attn, name)\n",
    "        \n",
    "        new_matrix = RotatedLinearIn(\n",
    "            original_matrix.in_features,\n",
    "            original_matrix.out_features,\n",
    "            original_matrix.bias is not None,\n",
    "            original_matrix.weight.data.device,\n",
    "            original_matrix.weight.data.dtype,\n",
    "            Q\n",
    "        )\n",
    "        \n",
    "        new_matrix.weight.data = original_matrix.weight.data.clone()\n",
    "        if original_matrix.bias is not None:\n",
    "            new_matrix.bias.data = original_matrix.bias.data.clone()\n",
    "        \n",
    "        setattr(layer.self_attn, name, new_matrix)\n",
    "        del original_matrix\n",
    "\n",
    "\n",
    "def rotate_attention_output(layer, Q) -> None:\n",
    "    # Rotate output matrix of the self-attention layer.\n",
    "    original_matrix = layer.self_attn.o_proj\n",
    "    \n",
    "    new_matrix = RotatedLinearOut(\n",
    "        original_matrix.in_features,\n",
    "        original_matrix.out_features,\n",
    "        original_matrix.bias is not None,\n",
    "        original_matrix.weight.data.device,\n",
    "        original_matrix.weight.data.dtype,\n",
    "        Q\n",
    "    )\n",
    "    \n",
    "    new_matrix.weight.data = original_matrix.weight.data.clone()\n",
    "    if original_matrix.bias is not None:\n",
    "        new_matrix.bias.data = original_matrix.bias.data.clone()\n",
    "    \n",
    "    setattr(layer.self_attn, 'o_proj', new_matrix)\n",
    "    del original_matrix\n",
    "\n",
    "\n",
    "def rotate_mlp_input(layer, Q):\n",
    "    # Rotate the MLP input weights.\n",
    "    \n",
    "    for name in ['up_proj', 'gate_proj']:\n",
    "        original_matrix = getattr(layer.mlp, name)\n",
    "        \n",
    "        new_matrix = RotatedLinearIn(\n",
    "            original_matrix.in_features,\n",
    "            original_matrix.out_features,\n",
    "            original_matrix.bias is not None,\n",
    "            original_matrix.weight.data.device,\n",
    "            original_matrix.weight.data.dtype,\n",
    "            Q\n",
    "        )\n",
    "        \n",
    "        new_matrix.weight.data = original_matrix.weight.data.clone()\n",
    "        if original_matrix.bias is not None:\n",
    "            new_matrix.bias.data = original_matrix.bias.data.clone()\n",
    "        \n",
    "        setattr(layer.mlp, name, new_matrix)\n",
    "        del original_matrix\n",
    "\n",
    "\n",
    "def rotate_mlp_output(layer, Q):\n",
    "    # Rotate the MLP output weights and bias.\n",
    "    original_matrix = layer.mlp.down_proj\n",
    "    \n",
    "    new_matrix = RotatedLinearOut(\n",
    "        original_matrix.in_features,\n",
    "        original_matrix.out_features,\n",
    "        original_matrix.bias is not None,\n",
    "        original_matrix.weight.data.device,\n",
    "        original_matrix.weight.data.dtype,\n",
    "        Q\n",
    "    )\n",
    "    \n",
    "    new_matrix.weight.data = original_matrix.weight.data.clone()\n",
    "    if original_matrix.bias is not None:\n",
    "        new_matrix.bias.data = original_matrix.bias.data.clone()\n",
    "    \n",
    "    setattr(layer.mlp, 'down_proj', new_matrix)\n",
    "    del original_matrix\n",
    "\n",
    "\n",
    "def rotate_head(model, Q: torch.Tensor) -> None:\n",
    "    # Rotate the head.\n",
    "    original_matrix = model.lm_head\n",
    "    \n",
    "    new_matrix = RotatedLinearIn(\n",
    "        original_matrix.in_features,\n",
    "        original_matrix.out_features,\n",
    "        original_matrix.bias is not None,\n",
    "        original_matrix.weight.data.device,\n",
    "        original_matrix.weight.data.dtype,\n",
    "        Q\n",
    "    )\n",
    "    \n",
    "    new_matrix.weight.data = original_matrix.weight.data.clone()\n",
    "    if original_matrix.bias is not None:\n",
    "        new_matrix.bias.data = original_matrix.bias.data.clone()\n",
    "    \n",
    "    setattr(model, 'lm_head', new_matrix)\n",
    "    del original_matrix\n",
    "\n",
    "\n",
    "def rotate_ov_proj(layer, Q1, Q2, nheads):\n",
    "    #print(nheads)\n",
    "    original_matrix = layer.self_attn.o_proj\n",
    "    \n",
    "    new_matrix = RotatedOVProj(\n",
    "        original_matrix.in_features,\n",
    "        original_matrix.out_features,\n",
    "        original_matrix.bias is not None,\n",
    "        original_matrix.weight.data.device,\n",
    "        original_matrix.weight.data.dtype,\n",
    "        Q2, Q1, False, nheads\n",
    "    )\n",
    "    \n",
    "    new_matrix.weight.data = original_matrix.weight.data.clone()\n",
    "    if original_matrix.bias is not None:\n",
    "        new_matrix.bias.data = original_matrix.bias.data.clone()\n",
    "    \n",
    "    setattr(layer.self_attn, 'o_proj', new_matrix)\n",
    "    del original_matrix\n",
    "    \n",
    "    original_matrix = layer.self_attn.v_proj\n",
    "    \n",
    "    new_matrix = RotatedOVProj(\n",
    "        original_matrix.in_features,\n",
    "        original_matrix.out_features,\n",
    "        original_matrix.bias is not None,\n",
    "        original_matrix.weight.data.device,\n",
    "        original_matrix.weight.data.dtype,\n",
    "        Q1, Q2, True, nheads\n",
    "    )\n",
    "    \n",
    "    new_matrix.weight.data = original_matrix.weight.data.clone()\n",
    "    if original_matrix.bias is not None:\n",
    "        new_matrix.bias.data = original_matrix.bias.data.clone()\n",
    "    \n",
    "    setattr(layer.self_attn, 'v_proj', new_matrix)\n",
    "    del original_matrix\n",
    "\n",
    "\n",
    "def rotate_model(model, args):\n",
    "    #q = random_orthogonal_matrix(model.config.hidden_size, utils.DEV).to(dtype=torch.float32)\n",
    "    \n",
    "    config = model.config\n",
    "    num_heads = config.num_attention_heads\n",
    "    model_dim = config.hidden_size\n",
    "    head_dim = model_dim // num_heads\n",
    "    \n",
    "    q1 = random_hadamard_matrix(model.config.hidden_size, utils.DEV).to(dtype=torch.float64)\n",
    "    Q1 = nn.Parameter(q1, requires_grad=True)\n",
    "    Q2s = []\n",
    "    #q2 = random_hadamard_matrix(head_dim, utils.DEV).to(dtype=torch.float32)\n",
    "    #Q2 = nn.Parameter(q2, requires_grad=True)\n",
    "    \n",
    "    model_type = model_utils.model_type_extractor(model)\n",
    "    rotate_embeddings(model, Q1)\n",
    "    rotate_head(model, Q1)\n",
    "    utils.cleanup_memory()\n",
    "    layers = model_utils.get_transformer_layers(model, \n",
    "                                                model_type=model_type)\n",
    "    \n",
    "    for idx, layer in enumerate(tqdm.tqdm(layers, unit=\"layer\", desc=\"Rotating\")):\n",
    "        q2 = random_hadamard_matrix(head_dim, layers[idx].self_attn.v_proj.weight.device).to(dtype=torch.float64)#.clone().detach().requires_grad_(True)\n",
    "        Q2 = nn.Parameter(q2, requires_grad=True)\n",
    "        rotate_attention_inputs(layers[idx], Q1)\n",
    "        #rotate_attention_output(layers[idx], Q1)\n",
    "        rotate_mlp_input(layers[idx], Q1)\n",
    "        rotate_mlp_output(layers[idx], Q1)\n",
    "        rotate_ov_proj(layers[idx], Q1, Q2, num_heads)\n",
    "        \n",
    "        Q2s.append(Q2)\n",
    "        #print(str(idx) + '-----------')\n",
    "        #print(layer.self_attn.v_proj)\n",
    "        #print(layer.self_attn.o_proj)\n",
    "    return Q1, Q2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arguments: \n",
      "{'a_asym': False,\n",
      " 'a_bits': 4,\n",
      " 'a_clip_ratio': 1.0,\n",
      " 'a_groupsize': -1,\n",
      " 'act_order': False,\n",
      " 'bsz': 1,\n",
      " 'cal_dataset': 'wikitext2',\n",
      " 'capture_layer_io': False,\n",
      " 'distribute': False,\n",
      " 'eval_dataset': 'wikitext2',\n",
      " 'fp32_had': False,\n",
      " 'hf_token': None,\n",
      " 'int8_down_proj': False,\n",
      " 'k_asym': False,\n",
      " 'k_bits': 4,\n",
      " 'k_clip_ratio': 1.0,\n",
      " 'k_groupsize': -1,\n",
      " 'k_pre_rope': False,\n",
      " 'layer_idx': 10,\n",
      " 'learn_r1': True,\n",
      " 'learn_r2': True,\n",
      " 'lm_eval': False,\n",
      " 'lm_eval_batch_size': 128,\n",
      " 'load_qmodel_path': None,\n",
      " 'model': 'meta-llama/Llama-2-7b-hf',\n",
      " 'momentum': 0.0,\n",
      " 'nsamples': 128,\n",
      " 'percdamp': 0.01,\n",
      " 'prefix_r': '',\n",
      " 'rotate': True,\n",
      " 'rotate_mode': 'hadamard',\n",
      " 'rotation_seed': -1,\n",
      " 'save_name': '20240712_120507',\n",
      " 'save_path': '/ceph/echoi/codes/QuaRot/fake_quant/experiments/meta-llama/Llama-2-7b-hf/20240712_120507',\n",
      " 'save_qmodel_path': None,\n",
      " 'seed': 0,\n",
      " 'tasks': ['piqa',\n",
      "           'hellaswag',\n",
      "           'arc_easy',\n",
      "           'arc_challenge',\n",
      "           'winogrande',\n",
      "           'lambada'],\n",
      " 'v_asym': False,\n",
      " 'v_bits': 4,\n",
      " 'v_clip_ratio': 1.0,\n",
      " 'v_groupsize': -1,\n",
      " 'w_asym': False,\n",
      " 'w_bits': 4,\n",
      " 'w_clip': True,\n",
      " 'w_groupsize': -1,\n",
      " 'w_rtn': False,\n",
      " 'wandb': False,\n",
      " 'wandb_id': None,\n",
      " 'wandb_project': None}\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "args = utils.parser_gen('--model meta-llama/Llama-2-7b-hf --rotate --a_bits 4 --v_bits 4 --k_bits 4 --w_bits 4 --w_clip --bsz 1'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]\n",
      "---> Loading meta-llama/Llama-2-7b-hf Model with seq_len: 2048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.set_seed(args.seed)\n",
    "model = model_utils.get_model(args.model, args.hf_token)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.float16\n",
      "model.layers.0.self_attn.q_proj.weight torch.float16\n",
      "model.layers.0.self_attn.k_proj.weight torch.float16\n",
      "model.layers.0.self_attn.v_proj.weight torch.float16\n",
      "model.layers.0.self_attn.o_proj.weight torch.float16\n",
      "model.layers.0.mlp.gate_proj.weight torch.float16\n",
      "model.layers.0.mlp.up_proj.weight torch.float16\n",
      "model.layers.0.mlp.down_proj.weight torch.float16\n",
      "model.layers.0.input_layernorm.weight torch.float16\n",
      "model.layers.0.post_attention_layernorm.weight torch.float16\n",
      "model.layers.1.self_attn.q_proj.weight torch.float16\n",
      "model.layers.1.self_attn.k_proj.weight torch.float16\n",
      "model.layers.1.self_attn.v_proj.weight torch.float16\n",
      "model.layers.1.self_attn.o_proj.weight torch.float16\n",
      "model.layers.1.mlp.gate_proj.weight torch.float16\n",
      "model.layers.1.mlp.up_proj.weight torch.float16\n",
      "model.layers.1.mlp.down_proj.weight torch.float16\n",
      "model.layers.1.input_layernorm.weight torch.float16\n",
      "model.layers.1.post_attention_layernorm.weight torch.float16\n",
      "model.layers.2.self_attn.q_proj.weight torch.float16\n",
      "model.layers.2.self_attn.k_proj.weight torch.float16\n",
      "model.layers.2.self_attn.v_proj.weight torch.float16\n",
      "model.layers.2.self_attn.o_proj.weight torch.float16\n",
      "model.layers.2.mlp.gate_proj.weight torch.float16\n",
      "model.layers.2.mlp.up_proj.weight torch.float16\n",
      "model.layers.2.mlp.down_proj.weight torch.float16\n",
      "model.layers.2.input_layernorm.weight torch.float16\n",
      "model.layers.2.post_attention_layernorm.weight torch.float16\n",
      "model.layers.3.self_attn.q_proj.weight torch.float16\n",
      "model.layers.3.self_attn.k_proj.weight torch.float16\n",
      "model.layers.3.self_attn.v_proj.weight torch.float16\n",
      "model.layers.3.self_attn.o_proj.weight torch.float16\n",
      "model.layers.3.mlp.gate_proj.weight torch.float16\n",
      "model.layers.3.mlp.up_proj.weight torch.float16\n",
      "model.layers.3.mlp.down_proj.weight torch.float16\n",
      "model.layers.3.input_layernorm.weight torch.float16\n",
      "model.layers.3.post_attention_layernorm.weight torch.float16\n",
      "model.layers.4.self_attn.q_proj.weight torch.float16\n",
      "model.layers.4.self_attn.k_proj.weight torch.float16\n",
      "model.layers.4.self_attn.v_proj.weight torch.float16\n",
      "model.layers.4.self_attn.o_proj.weight torch.float16\n",
      "model.layers.4.mlp.gate_proj.weight torch.float16\n",
      "model.layers.4.mlp.up_proj.weight torch.float16\n",
      "model.layers.4.mlp.down_proj.weight torch.float16\n",
      "model.layers.4.input_layernorm.weight torch.float16\n",
      "model.layers.4.post_attention_layernorm.weight torch.float16\n",
      "model.layers.5.self_attn.q_proj.weight torch.float16\n",
      "model.layers.5.self_attn.k_proj.weight torch.float16\n",
      "model.layers.5.self_attn.v_proj.weight torch.float16\n",
      "model.layers.5.self_attn.o_proj.weight torch.float16\n",
      "model.layers.5.mlp.gate_proj.weight torch.float16\n",
      "model.layers.5.mlp.up_proj.weight torch.float16\n",
      "model.layers.5.mlp.down_proj.weight torch.float16\n",
      "model.layers.5.input_layernorm.weight torch.float16\n",
      "model.layers.5.post_attention_layernorm.weight torch.float16\n",
      "model.layers.6.self_attn.q_proj.weight torch.float16\n",
      "model.layers.6.self_attn.k_proj.weight torch.float16\n",
      "model.layers.6.self_attn.v_proj.weight torch.float16\n",
      "model.layers.6.self_attn.o_proj.weight torch.float16\n",
      "model.layers.6.mlp.gate_proj.weight torch.float16\n",
      "model.layers.6.mlp.up_proj.weight torch.float16\n",
      "model.layers.6.mlp.down_proj.weight torch.float16\n",
      "model.layers.6.input_layernorm.weight torch.float16\n",
      "model.layers.6.post_attention_layernorm.weight torch.float16\n",
      "model.layers.7.self_attn.q_proj.weight torch.float16\n",
      "model.layers.7.self_attn.k_proj.weight torch.float16\n",
      "model.layers.7.self_attn.v_proj.weight torch.float16\n",
      "model.layers.7.self_attn.o_proj.weight torch.float16\n",
      "model.layers.7.mlp.gate_proj.weight torch.float16\n",
      "model.layers.7.mlp.up_proj.weight torch.float16\n",
      "model.layers.7.mlp.down_proj.weight torch.float16\n",
      "model.layers.7.input_layernorm.weight torch.float16\n",
      "model.layers.7.post_attention_layernorm.weight torch.float16\n",
      "model.layers.8.self_attn.q_proj.weight torch.float16\n",
      "model.layers.8.self_attn.k_proj.weight torch.float16\n",
      "model.layers.8.self_attn.v_proj.weight torch.float16\n",
      "model.layers.8.self_attn.o_proj.weight torch.float16\n",
      "model.layers.8.mlp.gate_proj.weight torch.float16\n",
      "model.layers.8.mlp.up_proj.weight torch.float16\n",
      "model.layers.8.mlp.down_proj.weight torch.float16\n",
      "model.layers.8.input_layernorm.weight torch.float16\n",
      "model.layers.8.post_attention_layernorm.weight torch.float16\n",
      "model.layers.9.self_attn.q_proj.weight torch.float16\n",
      "model.layers.9.self_attn.k_proj.weight torch.float16\n",
      "model.layers.9.self_attn.v_proj.weight torch.float16\n",
      "model.layers.9.self_attn.o_proj.weight torch.float16\n",
      "model.layers.9.mlp.gate_proj.weight torch.float16\n",
      "model.layers.9.mlp.up_proj.weight torch.float16\n",
      "model.layers.9.mlp.down_proj.weight torch.float16\n",
      "model.layers.9.input_layernorm.weight torch.float16\n",
      "model.layers.9.post_attention_layernorm.weight torch.float16\n",
      "model.layers.10.self_attn.q_proj.weight torch.float16\n",
      "model.layers.10.self_attn.k_proj.weight torch.float16\n",
      "model.layers.10.self_attn.v_proj.weight torch.float16\n",
      "model.layers.10.self_attn.o_proj.weight torch.float16\n",
      "model.layers.10.mlp.gate_proj.weight torch.float16\n",
      "model.layers.10.mlp.up_proj.weight torch.float16\n",
      "model.layers.10.mlp.down_proj.weight torch.float16\n",
      "model.layers.10.input_layernorm.weight torch.float16\n",
      "model.layers.10.post_attention_layernorm.weight torch.float16\n",
      "model.layers.11.self_attn.q_proj.weight torch.float16\n",
      "model.layers.11.self_attn.k_proj.weight torch.float16\n",
      "model.layers.11.self_attn.v_proj.weight torch.float16\n",
      "model.layers.11.self_attn.o_proj.weight torch.float16\n",
      "model.layers.11.mlp.gate_proj.weight torch.float16\n",
      "model.layers.11.mlp.up_proj.weight torch.float16\n",
      "model.layers.11.mlp.down_proj.weight torch.float16\n",
      "model.layers.11.input_layernorm.weight torch.float16\n",
      "model.layers.11.post_attention_layernorm.weight torch.float16\n",
      "model.layers.12.self_attn.q_proj.weight torch.float16\n",
      "model.layers.12.self_attn.k_proj.weight torch.float16\n",
      "model.layers.12.self_attn.v_proj.weight torch.float16\n",
      "model.layers.12.self_attn.o_proj.weight torch.float16\n",
      "model.layers.12.mlp.gate_proj.weight torch.float16\n",
      "model.layers.12.mlp.up_proj.weight torch.float16\n",
      "model.layers.12.mlp.down_proj.weight torch.float16\n",
      "model.layers.12.input_layernorm.weight torch.float16\n",
      "model.layers.12.post_attention_layernorm.weight torch.float16\n",
      "model.layers.13.self_attn.q_proj.weight torch.float16\n",
      "model.layers.13.self_attn.k_proj.weight torch.float16\n",
      "model.layers.13.self_attn.v_proj.weight torch.float16\n",
      "model.layers.13.self_attn.o_proj.weight torch.float16\n",
      "model.layers.13.mlp.gate_proj.weight torch.float16\n",
      "model.layers.13.mlp.up_proj.weight torch.float16\n",
      "model.layers.13.mlp.down_proj.weight torch.float16\n",
      "model.layers.13.input_layernorm.weight torch.float16\n",
      "model.layers.13.post_attention_layernorm.weight torch.float16\n",
      "model.layers.14.self_attn.q_proj.weight torch.float16\n",
      "model.layers.14.self_attn.k_proj.weight torch.float16\n",
      "model.layers.14.self_attn.v_proj.weight torch.float16\n",
      "model.layers.14.self_attn.o_proj.weight torch.float16\n",
      "model.layers.14.mlp.gate_proj.weight torch.float16\n",
      "model.layers.14.mlp.up_proj.weight torch.float16\n",
      "model.layers.14.mlp.down_proj.weight torch.float16\n",
      "model.layers.14.input_layernorm.weight torch.float16\n",
      "model.layers.14.post_attention_layernorm.weight torch.float16\n",
      "model.layers.15.self_attn.q_proj.weight torch.float16\n",
      "model.layers.15.self_attn.k_proj.weight torch.float16\n",
      "model.layers.15.self_attn.v_proj.weight torch.float16\n",
      "model.layers.15.self_attn.o_proj.weight torch.float16\n",
      "model.layers.15.mlp.gate_proj.weight torch.float16\n",
      "model.layers.15.mlp.up_proj.weight torch.float16\n",
      "model.layers.15.mlp.down_proj.weight torch.float16\n",
      "model.layers.15.input_layernorm.weight torch.float16\n",
      "model.layers.15.post_attention_layernorm.weight torch.float16\n",
      "model.layers.16.self_attn.q_proj.weight torch.float16\n",
      "model.layers.16.self_attn.k_proj.weight torch.float16\n",
      "model.layers.16.self_attn.v_proj.weight torch.float16\n",
      "model.layers.16.self_attn.o_proj.weight torch.float16\n",
      "model.layers.16.mlp.gate_proj.weight torch.float16\n",
      "model.layers.16.mlp.up_proj.weight torch.float16\n",
      "model.layers.16.mlp.down_proj.weight torch.float16\n",
      "model.layers.16.input_layernorm.weight torch.float16\n",
      "model.layers.16.post_attention_layernorm.weight torch.float16\n",
      "model.layers.17.self_attn.q_proj.weight torch.float16\n",
      "model.layers.17.self_attn.k_proj.weight torch.float16\n",
      "model.layers.17.self_attn.v_proj.weight torch.float16\n",
      "model.layers.17.self_attn.o_proj.weight torch.float16\n",
      "model.layers.17.mlp.gate_proj.weight torch.float16\n",
      "model.layers.17.mlp.up_proj.weight torch.float16\n",
      "model.layers.17.mlp.down_proj.weight torch.float16\n",
      "model.layers.17.input_layernorm.weight torch.float16\n",
      "model.layers.17.post_attention_layernorm.weight torch.float16\n",
      "model.layers.18.self_attn.q_proj.weight torch.float16\n",
      "model.layers.18.self_attn.k_proj.weight torch.float16\n",
      "model.layers.18.self_attn.v_proj.weight torch.float16\n",
      "model.layers.18.self_attn.o_proj.weight torch.float16\n",
      "model.layers.18.mlp.gate_proj.weight torch.float16\n",
      "model.layers.18.mlp.up_proj.weight torch.float16\n",
      "model.layers.18.mlp.down_proj.weight torch.float16\n",
      "model.layers.18.input_layernorm.weight torch.float16\n",
      "model.layers.18.post_attention_layernorm.weight torch.float16\n",
      "model.layers.19.self_attn.q_proj.weight torch.float16\n",
      "model.layers.19.self_attn.k_proj.weight torch.float16\n",
      "model.layers.19.self_attn.v_proj.weight torch.float16\n",
      "model.layers.19.self_attn.o_proj.weight torch.float16\n",
      "model.layers.19.mlp.gate_proj.weight torch.float16\n",
      "model.layers.19.mlp.up_proj.weight torch.float16\n",
      "model.layers.19.mlp.down_proj.weight torch.float16\n",
      "model.layers.19.input_layernorm.weight torch.float16\n",
      "model.layers.19.post_attention_layernorm.weight torch.float16\n",
      "model.layers.20.self_attn.q_proj.weight torch.float16\n",
      "model.layers.20.self_attn.k_proj.weight torch.float16\n",
      "model.layers.20.self_attn.v_proj.weight torch.float16\n",
      "model.layers.20.self_attn.o_proj.weight torch.float16\n",
      "model.layers.20.mlp.gate_proj.weight torch.float16\n",
      "model.layers.20.mlp.up_proj.weight torch.float16\n",
      "model.layers.20.mlp.down_proj.weight torch.float16\n",
      "model.layers.20.input_layernorm.weight torch.float16\n",
      "model.layers.20.post_attention_layernorm.weight torch.float16\n",
      "model.layers.21.self_attn.q_proj.weight torch.float16\n",
      "model.layers.21.self_attn.k_proj.weight torch.float16\n",
      "model.layers.21.self_attn.v_proj.weight torch.float16\n",
      "model.layers.21.self_attn.o_proj.weight torch.float16\n",
      "model.layers.21.mlp.gate_proj.weight torch.float16\n",
      "model.layers.21.mlp.up_proj.weight torch.float16\n",
      "model.layers.21.mlp.down_proj.weight torch.float16\n",
      "model.layers.21.input_layernorm.weight torch.float16\n",
      "model.layers.21.post_attention_layernorm.weight torch.float16\n",
      "model.layers.22.self_attn.q_proj.weight torch.float16\n",
      "model.layers.22.self_attn.k_proj.weight torch.float16\n",
      "model.layers.22.self_attn.v_proj.weight torch.float16\n",
      "model.layers.22.self_attn.o_proj.weight torch.float16\n",
      "model.layers.22.mlp.gate_proj.weight torch.float16\n",
      "model.layers.22.mlp.up_proj.weight torch.float16\n",
      "model.layers.22.mlp.down_proj.weight torch.float16\n",
      "model.layers.22.input_layernorm.weight torch.float16\n",
      "model.layers.22.post_attention_layernorm.weight torch.float16\n",
      "model.layers.23.self_attn.q_proj.weight torch.float16\n",
      "model.layers.23.self_attn.k_proj.weight torch.float16\n",
      "model.layers.23.self_attn.v_proj.weight torch.float16\n",
      "model.layers.23.self_attn.o_proj.weight torch.float16\n",
      "model.layers.23.mlp.gate_proj.weight torch.float16\n",
      "model.layers.23.mlp.up_proj.weight torch.float16\n",
      "model.layers.23.mlp.down_proj.weight torch.float16\n",
      "model.layers.23.input_layernorm.weight torch.float16\n",
      "model.layers.23.post_attention_layernorm.weight torch.float16\n",
      "model.layers.24.self_attn.q_proj.weight torch.float16\n",
      "model.layers.24.self_attn.k_proj.weight torch.float16\n",
      "model.layers.24.self_attn.v_proj.weight torch.float16\n",
      "model.layers.24.self_attn.o_proj.weight torch.float16\n",
      "model.layers.24.mlp.gate_proj.weight torch.float16\n",
      "model.layers.24.mlp.up_proj.weight torch.float16\n",
      "model.layers.24.mlp.down_proj.weight torch.float16\n",
      "model.layers.24.input_layernorm.weight torch.float16\n",
      "model.layers.24.post_attention_layernorm.weight torch.float16\n",
      "model.layers.25.self_attn.q_proj.weight torch.float16\n",
      "model.layers.25.self_attn.k_proj.weight torch.float16\n",
      "model.layers.25.self_attn.v_proj.weight torch.float16\n",
      "model.layers.25.self_attn.o_proj.weight torch.float16\n",
      "model.layers.25.mlp.gate_proj.weight torch.float16\n",
      "model.layers.25.mlp.up_proj.weight torch.float16\n",
      "model.layers.25.mlp.down_proj.weight torch.float16\n",
      "model.layers.25.input_layernorm.weight torch.float16\n",
      "model.layers.25.post_attention_layernorm.weight torch.float16\n",
      "model.layers.26.self_attn.q_proj.weight torch.float16\n",
      "model.layers.26.self_attn.k_proj.weight torch.float16\n",
      "model.layers.26.self_attn.v_proj.weight torch.float16\n",
      "model.layers.26.self_attn.o_proj.weight torch.float16\n",
      "model.layers.26.mlp.gate_proj.weight torch.float16\n",
      "model.layers.26.mlp.up_proj.weight torch.float16\n",
      "model.layers.26.mlp.down_proj.weight torch.float16\n",
      "model.layers.26.input_layernorm.weight torch.float16\n",
      "model.layers.26.post_attention_layernorm.weight torch.float16\n",
      "model.layers.27.self_attn.q_proj.weight torch.float16\n",
      "model.layers.27.self_attn.k_proj.weight torch.float16\n",
      "model.layers.27.self_attn.v_proj.weight torch.float16\n",
      "model.layers.27.self_attn.o_proj.weight torch.float16\n",
      "model.layers.27.mlp.gate_proj.weight torch.float16\n",
      "model.layers.27.mlp.up_proj.weight torch.float16\n",
      "model.layers.27.mlp.down_proj.weight torch.float16\n",
      "model.layers.27.input_layernorm.weight torch.float16\n",
      "model.layers.27.post_attention_layernorm.weight torch.float16\n",
      "model.layers.28.self_attn.q_proj.weight torch.float16\n",
      "model.layers.28.self_attn.k_proj.weight torch.float16\n",
      "model.layers.28.self_attn.v_proj.weight torch.float16\n",
      "model.layers.28.self_attn.o_proj.weight torch.float16\n",
      "model.layers.28.mlp.gate_proj.weight torch.float16\n",
      "model.layers.28.mlp.up_proj.weight torch.float16\n",
      "model.layers.28.mlp.down_proj.weight torch.float16\n",
      "model.layers.28.input_layernorm.weight torch.float16\n",
      "model.layers.28.post_attention_layernorm.weight torch.float16\n",
      "model.layers.29.self_attn.q_proj.weight torch.float16\n",
      "model.layers.29.self_attn.k_proj.weight torch.float16\n",
      "model.layers.29.self_attn.v_proj.weight torch.float16\n",
      "model.layers.29.self_attn.o_proj.weight torch.float16\n",
      "model.layers.29.mlp.gate_proj.weight torch.float16\n",
      "model.layers.29.mlp.up_proj.weight torch.float16\n",
      "model.layers.29.mlp.down_proj.weight torch.float16\n",
      "model.layers.29.input_layernorm.weight torch.float16\n",
      "model.layers.29.post_attention_layernorm.weight torch.float16\n",
      "model.layers.30.self_attn.q_proj.weight torch.float16\n",
      "model.layers.30.self_attn.k_proj.weight torch.float16\n",
      "model.layers.30.self_attn.v_proj.weight torch.float16\n",
      "model.layers.30.self_attn.o_proj.weight torch.float16\n",
      "model.layers.30.mlp.gate_proj.weight torch.float16\n",
      "model.layers.30.mlp.up_proj.weight torch.float16\n",
      "model.layers.30.mlp.down_proj.weight torch.float16\n",
      "model.layers.30.input_layernorm.weight torch.float16\n",
      "model.layers.30.post_attention_layernorm.weight torch.float16\n",
      "model.layers.31.self_attn.q_proj.weight torch.float16\n",
      "model.layers.31.self_attn.k_proj.weight torch.float16\n",
      "model.layers.31.self_attn.v_proj.weight torch.float16\n",
      "model.layers.31.self_attn.o_proj.weight torch.float16\n",
      "model.layers.31.mlp.gate_proj.weight torch.float16\n",
      "model.layers.31.mlp.up_proj.weight torch.float16\n",
      "model.layers.31.mlp.down_proj.weight torch.float16\n",
      "model.layers.31.input_layernorm.weight torch.float16\n",
      "model.layers.31.post_attention_layernorm.weight torch.float16\n",
      "model.norm.weight torch.float16\n",
      "lm_head.weight torch.float16\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name, p.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU memory (from <module>): 0.00 -> 0.00 GB (0.00 GB)\n",
      "GPU memory (from distribute_model): 12.62 -> 12.62 GB (0.00 GB)\n"
     ]
    }
   ],
   "source": [
    "rotation_utils.fuse_layer_norms(model)\n",
    "utils.cleanup_memory(verbos=True)\n",
    "utils.distribute_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU memory (from rotate_model): 13.30 -> 12.68 GB (-0.61 GB)\n",
      "Rotating: 100%|██████████| 32/32 [00:00<00:00, 283.84layer/s]\n",
      "GPU memory (from <module>): 25.56 -> 13.37 GB (-12.19 GB)\n"
     ]
    }
   ],
   "source": [
    "Q1, Q2s = rotate_model(model, args)\n",
    "utils.cleanup_memory(verbos=True)\n",
    "\n",
    "# quant_utils.add_actquant(\n",
    "#     model,\n",
    "#     layers=[nn.Linear,\n",
    "#             ActQuantWrapper,\n",
    "#             RotatedHead,\n",
    "#             RotatedLinearIn,\n",
    "#             RotatedLinearOut,\n",
    "#             RotatedOVProj]\n",
    "# )\n",
    "\n",
    "# qlayers = quant_utils.find_qlayers(model.model, [nn.Linear, ActQuantWrapper, RotatedHead, RotatedLinearIn, RotatedLinearOut, RotatedOVProj])\n",
    "\n",
    "# for name in qlayers:\n",
    "#     if 'down_proj' in name:\n",
    "#         had_K, K = hadamard_utils.get_hadK(model.config.intermediate_size)\n",
    "#         qlayers[name].online_full_had = True\n",
    "#         qlayers[name].had_K = had_K\n",
    "#         qlayers[name].K = K\n",
    "#         qlayers[name].fp32_had = args.fp32_had\n",
    "#     if 'o_proj' in name:\n",
    "#         had_K, K = hadamard_utils.get_hadK(model.config.num_attention_heads)\n",
    "#         qlayers[name].online_partial_had = True\n",
    "#         qlayers[name].had_K = had_K\n",
    "#         qlayers[name].K = K\n",
    "#         qlayers[name].had_dim = model.config.hidden_size//model.config.num_attention_heads\n",
    "#         qlayers[name].fp32_had = args.fp32_had\n",
    "\n",
    "# rope_function_name = model_utils.get_rope_function_name(model)\n",
    "# layers = model_utils.get_layers(model)\n",
    "# k_quant_config = {'k_bits': 16, \"k_groupsize\": args.k_groupsize,\n",
    "#                     \"k_sym\": not(args.k_asym), \"k_clip_ratio\": args.k_clip_ratio}\n",
    "\n",
    "# for idx, layer in enumerate(layers):\n",
    "#     print('Wrapping QK', idx)\n",
    "#     rotation_utils.add_qk_rotation_wrapper_after_function_call_in_forward(\n",
    "#                 layer.self_attn, \n",
    "#                 rope_function_name, \n",
    "#                 config=model.config,\n",
    "#                 **k_quant_config)\n",
    "\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "Q1.requires_grad=True\n",
    "for Q2 in Q2s:\n",
    "    Q2.requires_grad=True\n",
    "\n",
    "#optimizer = torch.optim.Adam([Q1, Q2], lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = data_utils.get_loaders(\n",
    "    args.cal_dataset, nsamples=args.nsamples,\n",
    "    seed=args.seed, model=args.model,\n",
    "    seqlen=model.seqlen, eval_mode=False\n",
    ")\n",
    "\n",
    "from transformers.trainer_pt_utils import LabelSmoother\n",
    "label_smoother = LabelSmoother(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "pbar = tqdm.tqdm(range(0 + 1, 100 + 1), desc=\"Training progress\",\n",
    "            total=100, dynamic_ncols=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_stack = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Straightforward ortho reg w/ SFTT\n",
    "# for iteration in pbar:\n",
    "#     if not idx_stack:\n",
    "#         idx_stack = list(range(0, len(trainloader)))\n",
    "    \n",
    "#     idx = idx_stack.pop(randint(0, len(idx_stack) - 1))\n",
    "    \n",
    "#     data = trainloader[idx]\n",
    "    \n",
    "#     input = data[0]\n",
    "#     target = data[1]\n",
    "    \n",
    "#     output = model(input)\n",
    "    \n",
    "#     loss = label_smoother(output, input, shift_labels=True)\n",
    "#     sym = torch.mm(Q, torch.t(Q))\n",
    "#     sym -= torch.eye(Q.shape[0]).to(sym.device)\n",
    "#     # ls_ort = sym.abs().sum()   # poor match to geometry of orthogonal matrices\n",
    "#     ortho_reg = sym.pow(2.0).sum()\n",
    "#     loss = loss + 10.0 * ortho_reg\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         pbar.set_postfix(\n",
    "#             {'CE': f'{loss.item():.3f}',\n",
    "#             'Ortho': f'{ortho_reg.item():.3f}',\n",
    "#             'det(Q)': f'{torch.linalg.det(Q):.3f}'}\n",
    "#         )\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "# torch.save(Q, 'Q_Hreg1k.pt')\n",
    "# Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-forward hook-style test\n",
    "# q = random_orthogonal_matrix(2, device).to(dtype=torch.float32)\n",
    "\n",
    "# Q = nn.Parameter(q, requires_grad=True)\n",
    "\n",
    "# print('Q', Q)\n",
    "\n",
    "# layer = nn.Linear(2, 2, False).to(device)\n",
    "\n",
    "# for p in layer.parameters():\n",
    "#     p.requires_grad = False\n",
    "    \n",
    "# layer.register_buffer('Q', Q)\n",
    "\n",
    "# def hook(module, input):\n",
    "#     x = F.linear(input[0], module.Q)\n",
    "#     return (x,) + input[1:]\n",
    "\n",
    "# layer.register_forward_pre_hook(hook)\n",
    "\n",
    "# x = torch.eye(2).to(device)\n",
    "# target = torch.eye(2).to(device)\n",
    "\n",
    "# optim = torch.optim.Adam([Q], lr=1e-2)\n",
    "\n",
    "# for i in range(1000000):\n",
    "#     y = layer(x)\n",
    "#     loss = F.mse_loss(y, target)\n",
    "    \n",
    "#     sym = torch.mm(Q, torch.t(Q))\n",
    "#     sym -= torch.eye(Q.shape[0]).to(device)\n",
    "#     # ls_ort = sym.abs().sum()   # poor match to geometry of orthogonal matrices\n",
    "#     ortho_reg = sym.pow(2.0).sum()\n",
    "    \n",
    "#     loss = loss + 0.1 * ortho_reg\n",
    "    \n",
    "#     optim.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optim.step()\n",
    "    \n",
    "#     if i % 10000 == 0:\n",
    "#         #print(\"-----W-----\")\n",
    "#         #print(layer.weight)\n",
    "#         print(\"-----Q-----\")\n",
    "#         print(Q)\n",
    "#         with torch.no_grad():\n",
    "#             print(torch.linalg.det(Q).item(), ortho_reg.item())\n",
    "#         print(\"-----Y-----\")\n",
    "#         print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = torch.zeros_like(Q1).requires_grad_(False)\n",
    "M2s = []\n",
    "\n",
    "for Q2 in Q2s:\n",
    "    M2 = torch.zeros_like(Q2).requires_grad_(False)\n",
    "    M2s.append(M2)\n",
    "\n",
    "beta = 0.9\n",
    "epsilon = 1e-8\n",
    "s = 5\n",
    "\n",
    "@torch.no_grad()\n",
    "def cayley_sgd(X, M, l, beta, epsilon, q, s):\n",
    "    M = beta * M - X.grad\n",
    "    #print('M', M.isnan().any().item())\n",
    "    MK = torch.matmul(M, X.T)\n",
    "    W_hat = MK - 0.5 * torch.matmul(X, torch.matmul(X.T, MK))\n",
    "    #print('W_hat', W_hat.isnan().any().item())\n",
    "    W = W_hat - W_hat.T\n",
    "    \n",
    "    M = torch.matmul(W, X)\n",
    "    \n",
    "    alpha = min(l, 2. * q / (torch.norm(W) + epsilon))\n",
    "    #print('alpha', alpha)\n",
    "    Y = X + alpha * M\n",
    "    \n",
    "    for i in range(s):\n",
    "        Y = X + alpha / 2 * torch.matmul(W, X + Y)\n",
    "    \n",
    "    X.data = Y\n",
    "    X.grad.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(iter, total_iter, max_lr, min_lr):\n",
    "    return max_lr - iter / total_iter * (max_lr - min_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   1%|          | 1/100 [00:08<14:38,  8.88s/it, CE=1.801, ortho1=-0.000, ortho2=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   2%|▏         | 2/100 [00:17<13:46,  8.44s/it, CE=1.725, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   3%|▎         | 3/100 [00:24<13:12,  8.17s/it, CE=1.901, ortho1=-0.000, ortho2=0.000] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   4%|▍         | 4/100 [00:32<12:51,  8.03s/it, CE=1.074, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   5%|▌         | 5/100 [00:40<12:36,  7.96s/it, CE=1.887, ortho1=-0.000, ortho2=0.000] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   6%|▌         | 6/100 [00:48<12:23,  7.91s/it, CE=1.509, ortho1=-0.000, ortho2=0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   7%|▋         | 7/100 [00:56<12:09,  7.84s/it, CE=1.758, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   8%|▊         | 8/100 [01:03<12:01,  7.84s/it, CE=2.013, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:   9%|▉         | 9/100 [01:11<11:53,  7.84s/it, CE=1.449, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  10%|█         | 10/100 [01:19<11:46,  7.85s/it, CE=1.852, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  11%|█         | 11/100 [01:27<11:40,  7.87s/it, CE=1.910, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  12%|█▏        | 12/100 [01:35<11:34,  7.89s/it, CE=1.834, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  13%|█▎        | 13/100 [01:43<11:25,  7.88s/it, CE=2.189, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  14%|█▍        | 14/100 [01:51<11:21,  7.92s/it, CE=2.136, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  15%|█▌        | 15/100 [01:59<11:12,  7.91s/it, CE=1.591, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  16%|█▌        | 16/100 [02:07<11:03,  7.90s/it, CE=1.766, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  17%|█▋        | 17/100 [02:14<10:56,  7.90s/it, CE=1.645, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  18%|█▊        | 18/100 [02:23<10:51,  7.94s/it, CE=1.564, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  19%|█▉        | 19/100 [02:31<10:47,  7.99s/it, CE=2.075, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  20%|██        | 20/100 [02:39<10:38,  7.98s/it, CE=1.623, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  21%|██        | 21/100 [02:47<10:29,  7.97s/it, CE=1.642, ortho1=-0.000, ortho2=0.000] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  22%|██▏       | 22/100 [02:54<10:19,  7.94s/it, CE=1.613, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  23%|██▎       | 23/100 [03:02<10:10,  7.93s/it, CE=1.514, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  24%|██▍       | 24/100 [03:10<10:03,  7.95s/it, CE=1.578, ortho1=-0.000, ortho2=-0.000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training progress:  25%|██▌       | 25/100 [03:18<09:56,  7.96s/it, CE=1.837, ortho1=-0.000, ortho2=0.000] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 0\n"
     ]
    }
   ],
   "source": [
    "for iteration in pbar:\n",
    "    if not idx_stack:\n",
    "        idx_stack = list(range(0, len(trainloader)))\n",
    "    \n",
    "    idx = idx_stack.pop(randint(0, len(idx_stack) - 1))\n",
    "    \n",
    "    data = trainloader[idx]\n",
    "    \n",
    "    input = data[0]\n",
    "    target = data[1]\n",
    "    #print()\n",
    "    output = model(input)\n",
    "    \n",
    "    loss = label_smoother(output, input, shift_labels=True)\n",
    "    \n",
    "    #Q1.retain_grad()\n",
    "    #for Q2 in Q2s:\n",
    "    #    Q2.retain_grad()\n",
    "    loss.backward()\n",
    "    lr = lr_schedule(iteration, 100, 1.5, 0)\n",
    "    #print(iteration, output['logits'].isnan().any().item(), loss.isnan().any().item(), lr)\n",
    "    cayley_sgd(Q1, M1, lr, 0.9, 1e-8, 0.5, 5)\n",
    "    count = 0\n",
    "    for Q2, M2 in zip(Q2s, M2s):\n",
    "        cayley_sgd(Q2, M2, lr, 0.9, 1e-8, 0.5, 5)\n",
    "        #if Q2.grad is not None:\n",
    "        #    count += 1\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                _ = torch.linalg.cholesky(Q2)\n",
    "            count += 1\n",
    "        except:\n",
    "            pass\n",
    "    print(iteration, count)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar.set_postfix(\n",
    "            {'CE': f'{loss.item():.3f}',\n",
    "             'ortho1': f'{(torch.matmul(Q1, Q1.T) - torch.eye(Q1.size(0)).to(Q1.device)).sum().item():.3f}',\n",
    "             'ortho2': f'{(torch.matmul(Q2, Q2.T) - torch.eye(Q2.size(0)).to(Q2.device)).sum().item():.3f}',\n",
    "             #'det(Q)': f'{torch.linalg.det(Q):.3f}'\n",
    "             }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0156, -0.0158, -0.0156,  ..., -0.0156, -0.0156, -0.0156],\n",
       "        [ 0.0156, -0.0157,  0.0157,  ..., -0.0157,  0.0156, -0.0156],\n",
       "        [ 0.0157,  0.0156, -0.0156,  ...,  0.0157, -0.0156, -0.0157],\n",
       "        ...,\n",
       "        [-0.0155,  0.0155, -0.0155,  ...,  0.0156, -0.0157,  0.0156],\n",
       "        [-0.0156, -0.0156,  0.0156,  ..., -0.0157,  0.0157,  0.0157],\n",
       "        [-0.0156,  0.0155,  0.0156,  ...,  0.0157,  0.0155, -0.0157]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0884,  ...,  0.0884,  0.0884,  0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0884,  ...,  0.0884,  0.0884,  0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0884,  ...,  0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:1', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0883, -0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0884,  ...,  0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0883],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0883,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0883,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0883,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0883],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0885,  0.0884,  ..., -0.0884,  0.0884, -0.0885],\n",
      "        [ 0.0884,  0.0883, -0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [-0.0883,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0883, -0.0884,  0.0883,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0883, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0883, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0883,  ...,  0.0884,  0.0885,  0.0884],\n",
      "        [ 0.0884, -0.0883,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0883, -0.0884,  0.0884,  ..., -0.0885,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0883, -0.0885, -0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0883, -0.0884]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0884,  ...,  0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0883, -0.0884,  0.0883],\n",
      "        [ 0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884, -0.0885],\n",
      "        ...,\n",
      "        [ 0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0885, -0.0884, -0.0883],\n",
      "        [ 0.0884, -0.0883, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0884,  ...,  0.0884,  0.0883,  0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0883,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [ 0.0883, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [ 0.0884, -0.0883, -0.0884,  ...,  0.0884,  0.0883, -0.0884]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0884, -0.0884, -0.0884,  ..., -0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0883, -0.0884,  ...,  0.0884, -0.0885,  0.0885],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0885],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0883,  0.0884,  ...,  0.0884, -0.0884, -0.0883],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0884,  ...,  0.0883,  0.0884,  0.0884],\n",
      "        [ 0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0883],\n",
      "        [ 0.0883,  0.0884, -0.0885,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        ...,\n",
      "        [ 0.0883, -0.0884,  0.0884,  ...,  0.0884, -0.0884,  0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0885, -0.0884],\n",
      "        [ 0.0884, -0.0884, -0.0884,  ...,  0.0884,  0.0884, -0.0884]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0883,  0.0883,  0.0883,  ...,  0.0884,  0.0884,  0.0884],\n",
      "        [-0.0884,  0.0884, -0.0884,  ...,  0.0884, -0.0883,  0.0884],\n",
      "        [ 0.0884,  0.0883, -0.0884,  ...,  0.0883, -0.0885, -0.0883],\n",
      "        ...,\n",
      "        [-0.0883,  0.0884, -0.0883,  ..., -0.0884,  0.0883, -0.0883],\n",
      "        [-0.0884, -0.0883,  0.0885,  ...,  0.0884, -0.0884, -0.0885],\n",
      "        [-0.0884,  0.0883,  0.0884,  ..., -0.0884, -0.0883,  0.0884]],\n",
      "       device='cuda:3', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0884,  0.0884,  0.0884,  ...,  0.0884,  0.0884,  0.0884],\n",
      "        [ 0.0883, -0.0884,  0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ..., -0.0884,  0.0884,  0.0884],\n",
      "        ...,\n",
      "        [-0.0884,  0.0884, -0.0884,  ..., -0.0884,  0.0884, -0.0884],\n",
      "        [-0.0884, -0.0884,  0.0884,  ...,  0.0884, -0.0884, -0.0884],\n",
      "        [-0.0884,  0.0884,  0.0884,  ..., -0.0884, -0.0884,  0.0884]],\n",
      "       device='cuda:3', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for Q2 in Q2s:\n",
    "    print(Q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Q1, 'Q1.pt')\n",
    "for idx, Q2 in enumerate(Q2s):\n",
    "    torch.save(Q2, f'Q2_{idx}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mhead_dim\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.layers[0].self_attn.head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q2s[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
